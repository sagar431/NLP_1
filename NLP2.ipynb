{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff30fb93",
   "metadata": {},
   "source": [
    "1. What are Corpora?\n",
    "2. What are Tokens?\n",
    "3. What are Unigrams, Bigrams, Trigrams?\n",
    "4. How to generate n-grams from text?\n",
    "5. Explain Lemmatization\n",
    "6. Explain Stemming\n",
    "7. Explain Part-of-speech (POS) tagging\n",
    "8. Explain Chunking or shallow parsing\n",
    "9. Explain Noun Phrase (NP) chunking\n",
    "10. Explain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a32bf",
   "metadata": {},
   "source": [
    "1. Corpora is the plural of corpus, which refers to a collection of texts, usually in electronic form, that is used for linguistic research or analysis.\n",
    "\n",
    "2. Tokens are the individual units of a text, typically separated by whitespace or punctuation. They can be words, phrases, or other types of units, depending on the context.\n",
    "\n",
    "3. Unigrams, bigrams, and trigrams are types of n-grams, which are contiguous sequences of n tokens in a text. Unigrams are single words, bigrams are pairs of adjacent words, and trigrams are sequences of three adjacent words.\n",
    "\n",
    "4. N-grams can be generated from text by splitting the text into tokens and then grouping the tokens into sequences of n tokens.\n",
    "\n",
    "5. Lemmatization is the process of reducing a word to its base or dictionary form, known as a lemma. This involves identifying the part of speech of the word and applying morphological rules to reduce it to its base form.\n",
    "\n",
    "6. Stemming is the process of reducing a word to its stem or root form, typically by removing suffixes or prefixes. This is a simpler and faster method than lemmatization, but can result in non-words or incorrect words.\n",
    "\n",
    "7. Part-of-speech (POS) tagging is the process of assigning a grammatical category, or part of speech, to each token in a text, such as noun, verb, adjective, or adverb. This is typically done using statistical models or rule-based approaches.\n",
    "\n",
    "8. Chunking, also known as shallow parsing, is the process of identifying and grouping together adjacent tokens that form a syntactic unit, such as a noun phrase or verb phrase. This is typically done using regular expressions or statistical models.\n",
    "\n",
    "9. Noun phrase (NP) chunking is a type of chunking that focuses specifically on identifying and grouping together noun phrases in a text. This can be useful for tasks such as named entity recognition or text classification.\n",
    "\n",
    "10. Named entity recognition (NER) is the process of identifying and classifying named entities in a text, such as people, places, and organizations. This typically involves using machine learning models that have been trained on annotated text data. NER can be used for tasks such as information extraction or text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d687a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
